{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4 : Other nltk tokenizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize the following sentence using <br>\n",
    "i) Tweet Tokenizer <br>\n",
    "ii) MWE Tokenizer <br>\n",
    "iii) Regexp Tokenizer <br>\n",
    "iv) Whitespace Tokenizer <br>\n",
    "v) Word Punct Tokenizer <br>\n",
    "\n",
    "Sunil tweeted, “Witnessing 70th Republic Day of India from Rajpath, New Delhi. Mesmerizing performance by Indian Army. Awesome airshow! @india_official @indian_army  #India #70thRepublic_Day. For more photos ping me sunil@photoking.com :) ”\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'Sunil tweeted, \"Witnessing 70th Republic Day of India from Rajpath, \\\n",
    "New Delhi. Mesmerizing performance by Indian Army! Awesome airshow! @india_official \\\n",
    "@indian_army #India #70thRepublic_Day. For more photos ping me sunil@photoking.com :)\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sunil',\n",
       " 'tweeted',\n",
       " ',',\n",
       " '\"',\n",
       " 'Witnessing',\n",
       " '70th',\n",
       " 'Republic',\n",
       " 'Day',\n",
       " 'of',\n",
       " 'India',\n",
       " 'from',\n",
       " 'Rajpath',\n",
       " ',',\n",
       " 'New',\n",
       " 'Delhi',\n",
       " '.',\n",
       " 'Mesmerizing',\n",
       " 'performance',\n",
       " 'by',\n",
       " 'Indian',\n",
       " 'Army',\n",
       " '!',\n",
       " 'Awesome',\n",
       " 'airshow',\n",
       " '!',\n",
       " '@india_official',\n",
       " '@indian_army',\n",
       " '#India',\n",
       " '#70thRepublic_Day',\n",
       " '.',\n",
       " 'For',\n",
       " 'more',\n",
       " 'photos',\n",
       " 'ping',\n",
       " 'me',\n",
       " 'sunil@photoking.com',\n",
       " ':)',\n",
       " '\"']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#i) Tweet tokenizer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "tweet_tokenizer = TweetTokenizer()\n",
    "tweet_tokenizer.tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ii) MWE Tokenizer\n",
    "from nltk.tokenize import MWETokenizer\n",
    "mwe_tokenizer = MWETokenizer([('Republic', 'Day')]) #Declaring set of words that are to be treated as one entity\n",
    "mwe_tokenizer.add_mwe(('Indian', 'Army')) #Adding more words to the set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sunil',\n",
       " 'tweeted,',\n",
       " '\"Witnessing',\n",
       " '70th',\n",
       " 'Republic_Day',\n",
       " 'of',\n",
       " 'India',\n",
       " 'from',\n",
       " 'Rajpath,',\n",
       " 'New',\n",
       " 'Delhi.',\n",
       " 'Mesmerizing',\n",
       " 'performance',\n",
       " 'by',\n",
       " 'Indian',\n",
       " 'Army!',\n",
       " 'Awesome',\n",
       " 'airshow!',\n",
       " '@india_official',\n",
       " '@indian_army',\n",
       " '#India',\n",
       " '#70thRepublic_Day.',\n",
       " 'For',\n",
       " 'more',\n",
       " 'photos',\n",
       " 'ping',\n",
       " 'me',\n",
       " 'sunil@photoking.com',\n",
       " ':)\"']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mwe_tokenizer.tokenize(sentence.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did you observe that when the above line of code was executed words like \"Indian\" and \"Army\" which were supposed to be treated as single identity got separated. Do you know why? It happened because \"Army!\"  (not \"Army\") is treated as a token. Let's see how can this be fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sunil',\n",
       " 'tweeted,',\n",
       " '\"Witnessing',\n",
       " '70th',\n",
       " 'Republic_Day',\n",
       " 'of',\n",
       " 'India',\n",
       " 'from',\n",
       " 'Rajpath,',\n",
       " 'New',\n",
       " 'Delhi.',\n",
       " 'Mesmerizing',\n",
       " 'performance',\n",
       " 'by',\n",
       " 'Indian_Army',\n",
       " 'Awesome',\n",
       " 'airshow',\n",
       " '@india_official',\n",
       " '@indian_army',\n",
       " '#India',\n",
       " '#70thRepublic_Day.',\n",
       " 'For',\n",
       " 'more',\n",
       " 'photos',\n",
       " 'ping',\n",
       " 'me',\n",
       " 'sunil@photoking.com',\n",
       " ':)\"']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mwe_tokenizer.tokenize(sentence.replace('!','').split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sunil',\n",
       " 'tweeted',\n",
       " ',',\n",
       " '\"Witnessing',\n",
       " '70th',\n",
       " 'Republic',\n",
       " 'Day',\n",
       " 'of',\n",
       " 'India',\n",
       " 'from',\n",
       " 'Rajpath',\n",
       " ',',\n",
       " 'New',\n",
       " 'Delhi',\n",
       " '.',\n",
       " 'Mesmerizing',\n",
       " 'performance',\n",
       " 'by',\n",
       " 'Indian',\n",
       " 'Army',\n",
       " '!',\n",
       " 'Awesome',\n",
       " 'airshow',\n",
       " '!',\n",
       " '@india_official',\n",
       " '@indian_army',\n",
       " '#India',\n",
       " '#70thRepublic_Day.',\n",
       " 'For',\n",
       " 'more',\n",
       " 'photos',\n",
       " 'ping',\n",
       " 'me',\n",
       " 'sunil',\n",
       " '@photoking.com',\n",
       " ':)\"']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#iii) Regexp Tokenizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "reg_tokenizer = RegexpTokenizer('\\w+|\\$[\\d\\.]+|\\S+')\n",
    "reg_tokenizer.tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sunil',\n",
       " 'tweeted,',\n",
       " '\"Witnessing',\n",
       " '70th',\n",
       " 'Republic',\n",
       " 'Day',\n",
       " 'of',\n",
       " 'India',\n",
       " 'from',\n",
       " 'Rajpath,',\n",
       " 'New',\n",
       " 'Delhi.',\n",
       " 'Mesmerizing',\n",
       " 'performance',\n",
       " 'by',\n",
       " 'Indian',\n",
       " 'Army!',\n",
       " 'Awesome',\n",
       " 'airshow!',\n",
       " '@india_official',\n",
       " '@indian_army',\n",
       " '#India',\n",
       " '#70thRepublic_Day.',\n",
       " 'For',\n",
       " 'more',\n",
       " 'photos',\n",
       " 'ping',\n",
       " 'me',\n",
       " 'sunil@photoking.com',\n",
       " ':)\"']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#iv) Whitespace Tokenizer\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "wh_tokenizer = WhitespaceTokenizer()\n",
    "wh_tokenizer.tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sunil',\n",
       " 'tweeted',\n",
       " ',',\n",
       " '\"',\n",
       " 'Witnessing',\n",
       " '70th',\n",
       " 'Republic',\n",
       " 'Day',\n",
       " 'of',\n",
       " 'India',\n",
       " 'from',\n",
       " 'Rajpath',\n",
       " ',',\n",
       " 'New',\n",
       " 'Delhi',\n",
       " '.',\n",
       " 'Mesmerizing',\n",
       " 'performance',\n",
       " 'by',\n",
       " 'Indian',\n",
       " 'Army',\n",
       " '!',\n",
       " 'Awesome',\n",
       " 'airshow',\n",
       " '!',\n",
       " '@',\n",
       " 'india_official',\n",
       " '@',\n",
       " 'indian_army',\n",
       " '#',\n",
       " 'India',\n",
       " '#',\n",
       " '70thRepublic_Day',\n",
       " '.',\n",
       " 'For',\n",
       " 'more',\n",
       " 'photos',\n",
       " 'ping',\n",
       " 'me',\n",
       " 'sunil',\n",
       " '@',\n",
       " 'photoking',\n",
       " '.',\n",
       " 'com',\n",
       " ':)\"']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#v) WordPunct Tokenizer\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "wp_tokenizer = WordPunctTokenizer()\n",
    "wp_tokenizer.tokenize(sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
