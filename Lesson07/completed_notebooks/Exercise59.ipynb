{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Hot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hot Encoding Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "data = Path('data')\n",
    "movie_lines_file = data / '100lines.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "with movie_lines_file.open() as f:\n",
    "    movie_lines_raw = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'They do not!\\nThey do to!\\nI hope so.\\nShe okay?\\nLet\\'s go.\\nWow\\nOkay -- you\\'re gonna need to learn how to lie.\\nNo\\nI\\'m kidding.  You know how sometimes you just become this \"persona\"?  And you don\\'t know how to quit?\\nLike my fear of wearing pastels?\\nThe \"real you\".\\nWhat good stuff?\\nI figured you\\'d get to the good stuff eventually.\\nThank God!  If I had to hear one more story about your coiffure...\\nMe.  This endless ...blonde babble. I\\'m like, boring myself.\\nWhat crap?\\ndo you listen to this crap?\\nNo...\\nThen Guillermo says, \"If you go any lighter, you\\'re gonna look like an extra on 90210.\"\\nYou always been this selfish?\\nBut\\nThen that\\'s all you had to say.\\nWell, no...\\nYou never wanted to go out with \\'me, did you?\\nI was?\\nI looked for you back at the party, but you always seemed to be \"occupied\".\\nTons\\nHave fun tonight?\\nI believe we share an art instructor\\nYou know Chastity?\\nLooks like things worked out tonight, huh?\\nHi.\\nWho knows?  All I\\'ve ever heard her say is that she\\'d dip before dating a guy that smokes.\\nSo that\\'s the kind of guy she likes? Pretty ones?\\nLesbian?  No. I found a picture of Jared Leto in one of her drawers, so I\\'m pretty sure she\\'s not harboring same-sex tendencies.\\nShe\\'s not a...\\nI\\'m workin\\' on it. But she doesn\\'t seem to be goin\\' for him.\\nI really, really, really wanna go, but I can\\'t.  Not unless my sister goes.\\nSure have.\\nEber\\'s Deep Conditioner every two days. And I never, ever use a blowdryer without the diffuser attachment.\\nHow do you get your hair to look like that?\\nYou\\'re sweet.\\nYou have my word.  As a gentleman\\nI counted on you to help my cause. You and that thug are obviously failing. Aren\\'t we ever going on our date?\\nYou got something on your mind?\\nWhere?\\nThere.\\nWell, there\\'s someone I think might be --\\nHow is our little Find the Wench A Date plan progressing?\\nForget French.\\nThat\\'s because it\\'s such a nice one.\\nI don\\'t want to know how to say that though.  I want to know useful things. Like where the good stores are.  How much does champagne cost?  Stuff like Chat.  I have never in my life had to point out my head to someone.\\nRight.  See?  You\\'re ready for the quiz.\\nC\\'esc ma tete. This is my head\\nLet me see what I can do.\\nGosh, if only we could find Kat a boyfriend...\\nThat\\'s a shame.\\nUnsolved mystery.  She used to be really popular when she started high school, then it was just like she got sick of it or something.\\nWhy?\\nSeems like she could get a date easy enough...\\nThe thing is,  -- I\\'m at the mercy of a particularly hideous breed of loser.  My sister.  I can\\'t date until she does.\\n.\\nNo, no, it\\'s my fault -- we didn\\'t have a proper introduction ---\\nForget it.\\nYou\\'re asking me out.  That\\'s so cute. What\\'s your name again?\\nOkay... then how \\'bout we try out some French cuisine.  Saturday?  Night?\\nNot the hacking and gagging and spitting part.  Please.\\nWell, I thought we\\'d start with pronunciation, if that\\'s okay with you.\\nCan we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.\\nI did.\\nYou think you \\' re the only sophomore at the prom?\\nI don\\'t have to be home \\'til two.\\nI have to be home in twenty minutes.\\nAll I know is -- I\\'d give up my private line to go out with a guy like Joey.\\nSometimes I wonder if the guys we\\'re supposed to want to go out with are the ones we actually want to go out with, you know?\\n, I don\\'t think the highlights of dating Joey Dorsey are going to include door-opening and coat-holding.\\nCombination.  I don\\'t know -- I thought he\\'d be different.  More of a gentleman...\\nIs he oily or dry?\\nHe practically proposed when he found out we had the same dermatologist. I mean. Dr. Bonchowski is great an all, but he\\'s not exactly relevant party conversation.\\nWould you mind getting me a drink, ?\\nGreat\\nJoey.\\nWho?\\nWhere did he go?  He was just here.\\nYou might wanna think about it\\nNo.\\nDid you change your hair?\\nYou know the deal.  I can \\' t go if Kat doesn\\'t go --\\nListen, I want to talk to you about the prom.\\nYou\\'re concentrating awfully hard considering it\\'s gym class.\\nHi, Joey.\\nHey, sweet cheeks.\\nMy agent says I\\'ve got a good shot at being the Prada guy next year.\\nNeat...\\nIt\\'s a cruise line, but I\\'ll be, like, wearing a uniform and stuff.\\nQueen Harry?\\nSo yeah, I\\'ve got the Sears catalog thing going -- and the tube sock gig \" that\\'s gonna be huge.  And then I\\'m up for an ad for Queen Harry next week.\\nHopefully.\\nExactly  So, you going to Bogey Lowenbrau\\'s thing on Saturday?\\nExpensive?'"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_lines_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "alpha_characters = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "def clean_tokenize(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\n', '*** ', text)\n",
    "    text = text.translate(alpha_characters)\n",
    "    text = re.sub(r' +', ' ', text)\n",
    "    return text.split(' ')\n",
    "\n",
    "movie_lines = clean_tokenize(movie_lines_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['they',\n",
       " 'do',\n",
       " 'not',\n",
       " 'they',\n",
       " 'do',\n",
       " 'to',\n",
       " 'i',\n",
       " 'hope',\n",
       " 'so',\n",
       " 'she',\n",
       " 'okay',\n",
       " 'lets',\n",
       " 'go',\n",
       " 'wow',\n",
       " 'okay',\n",
       " 'youre',\n",
       " 'gonna',\n",
       " 'need',\n",
       " 'to',\n",
       " 'learn',\n",
       " 'how',\n",
       " 'to',\n",
       " 'lie',\n",
       " 'no',\n",
       " 'im',\n",
       " 'kidding',\n",
       " 'you',\n",
       " 'know',\n",
       " 'how',\n",
       " 'sometimes',\n",
       " 'you',\n",
       " 'just',\n",
       " 'become',\n",
       " 'this',\n",
       " 'persona',\n",
       " 'and',\n",
       " 'you',\n",
       " 'dont',\n",
       " 'know',\n",
       " 'how',\n",
       " 'to',\n",
       " 'quit',\n",
       " 'like',\n",
       " 'my',\n",
       " 'fear',\n",
       " 'of',\n",
       " 'wearing',\n",
       " 'pastels',\n",
       " 'the',\n",
       " 'real',\n",
       " 'you',\n",
       " 'what',\n",
       " 'good',\n",
       " 'stuff',\n",
       " 'i',\n",
       " 'figured',\n",
       " 'youd',\n",
       " 'get',\n",
       " 'to',\n",
       " 'the',\n",
       " 'good',\n",
       " 'stuff',\n",
       " 'eventually',\n",
       " 'thank',\n",
       " 'god',\n",
       " 'if',\n",
       " 'i',\n",
       " 'had',\n",
       " 'to',\n",
       " 'hear',\n",
       " 'one',\n",
       " 'more',\n",
       " 'story',\n",
       " 'about',\n",
       " 'your',\n",
       " 'coiffure',\n",
       " 'me',\n",
       " 'this',\n",
       " 'endless',\n",
       " 'blonde',\n",
       " 'babble',\n",
       " 'im',\n",
       " 'like',\n",
       " 'boring',\n",
       " 'myself',\n",
       " 'what',\n",
       " 'crap',\n",
       " 'do',\n",
       " 'you',\n",
       " 'listen',\n",
       " 'to',\n",
       " 'this',\n",
       " 'crap',\n",
       " 'no',\n",
       " 'then',\n",
       " 'guillermo',\n",
       " 'says',\n",
       " 'if',\n",
       " 'you',\n",
       " 'go',\n",
       " 'any',\n",
       " 'lighter',\n",
       " 'youre',\n",
       " 'gonna',\n",
       " 'look',\n",
       " 'like',\n",
       " 'an',\n",
       " 'extra',\n",
       " 'on',\n",
       " '90210',\n",
       " 'you',\n",
       " 'always',\n",
       " 'been',\n",
       " 'this',\n",
       " 'selfish',\n",
       " 'but',\n",
       " 'then',\n",
       " 'thats',\n",
       " 'all',\n",
       " 'you',\n",
       " 'had',\n",
       " 'to',\n",
       " 'say',\n",
       " 'well',\n",
       " 'no',\n",
       " 'you',\n",
       " 'never',\n",
       " 'wanted',\n",
       " 'to',\n",
       " 'go',\n",
       " 'out',\n",
       " 'with',\n",
       " 'me',\n",
       " 'did',\n",
       " 'you',\n",
       " 'i',\n",
       " 'was',\n",
       " 'i',\n",
       " 'looked',\n",
       " 'for',\n",
       " 'you',\n",
       " 'back',\n",
       " 'at',\n",
       " 'the',\n",
       " 'party',\n",
       " 'but',\n",
       " 'you',\n",
       " 'always',\n",
       " 'seemed',\n",
       " 'to',\n",
       " 'be',\n",
       " 'occupied',\n",
       " 'tons',\n",
       " 'have',\n",
       " 'fun',\n",
       " 'tonight',\n",
       " 'i',\n",
       " 'believe',\n",
       " 'we',\n",
       " 'share',\n",
       " 'an',\n",
       " 'art',\n",
       " 'instructor',\n",
       " 'you',\n",
       " 'know',\n",
       " 'chastity',\n",
       " 'looks',\n",
       " 'like',\n",
       " 'things',\n",
       " 'worked',\n",
       " 'out',\n",
       " 'tonight',\n",
       " 'huh',\n",
       " 'hi',\n",
       " 'who',\n",
       " 'knows',\n",
       " 'all',\n",
       " 'ive',\n",
       " 'ever',\n",
       " 'heard',\n",
       " 'her',\n",
       " 'say',\n",
       " 'is',\n",
       " 'that',\n",
       " 'shed',\n",
       " 'dip',\n",
       " 'before',\n",
       " 'dating',\n",
       " 'a',\n",
       " 'guy',\n",
       " 'that',\n",
       " 'smokes',\n",
       " 'so',\n",
       " 'thats',\n",
       " 'the',\n",
       " 'kind',\n",
       " 'of',\n",
       " 'guy',\n",
       " 'she',\n",
       " 'likes',\n",
       " 'pretty',\n",
       " 'ones',\n",
       " 'lesbian',\n",
       " 'no',\n",
       " 'i',\n",
       " 'found',\n",
       " 'a',\n",
       " 'picture',\n",
       " 'of',\n",
       " 'jared',\n",
       " 'leto',\n",
       " 'in',\n",
       " 'one',\n",
       " 'of',\n",
       " 'her',\n",
       " 'drawers',\n",
       " 'so',\n",
       " 'im',\n",
       " 'pretty',\n",
       " 'sure',\n",
       " 'shes',\n",
       " 'not',\n",
       " 'harboring',\n",
       " 'samesex',\n",
       " 'tendencies',\n",
       " 'shes',\n",
       " 'not',\n",
       " 'a',\n",
       " 'im',\n",
       " 'workin',\n",
       " 'on',\n",
       " 'it',\n",
       " 'but',\n",
       " 'she',\n",
       " 'doesnt',\n",
       " 'seem',\n",
       " 'to',\n",
       " 'be',\n",
       " 'goin',\n",
       " 'for',\n",
       " 'him',\n",
       " 'i',\n",
       " 'really',\n",
       " 'really',\n",
       " 'really',\n",
       " 'wanna',\n",
       " 'go',\n",
       " 'but',\n",
       " 'i',\n",
       " 'cant',\n",
       " 'not',\n",
       " 'unless',\n",
       " 'my',\n",
       " 'sister',\n",
       " 'goes',\n",
       " 'sure',\n",
       " 'have',\n",
       " 'ebers',\n",
       " 'deep',\n",
       " 'conditioner',\n",
       " 'every',\n",
       " 'two',\n",
       " 'days',\n",
       " 'and',\n",
       " 'i',\n",
       " 'never',\n",
       " 'ever',\n",
       " 'use',\n",
       " 'a',\n",
       " 'blowdryer',\n",
       " 'without',\n",
       " 'the',\n",
       " 'diffuser',\n",
       " 'attachment',\n",
       " 'how',\n",
       " 'do',\n",
       " 'you',\n",
       " 'get',\n",
       " 'your',\n",
       " 'hair',\n",
       " 'to',\n",
       " 'look',\n",
       " 'like',\n",
       " 'that',\n",
       " 'youre',\n",
       " 'sweet',\n",
       " 'you',\n",
       " 'have',\n",
       " 'my',\n",
       " 'word',\n",
       " 'as',\n",
       " 'a',\n",
       " 'gentleman',\n",
       " 'i',\n",
       " 'counted',\n",
       " 'on',\n",
       " 'you',\n",
       " 'to',\n",
       " 'help',\n",
       " 'my',\n",
       " 'cause',\n",
       " 'you',\n",
       " 'and',\n",
       " 'that',\n",
       " 'thug',\n",
       " 'are',\n",
       " 'obviously',\n",
       " 'failing',\n",
       " 'arent',\n",
       " 'we',\n",
       " 'ever',\n",
       " 'going',\n",
       " 'on',\n",
       " 'our',\n",
       " 'date',\n",
       " 'you',\n",
       " 'got',\n",
       " 'something',\n",
       " 'on',\n",
       " 'your',\n",
       " 'mind',\n",
       " 'where',\n",
       " 'there',\n",
       " 'well',\n",
       " 'theres',\n",
       " 'someone',\n",
       " 'i',\n",
       " 'think',\n",
       " 'might',\n",
       " 'be',\n",
       " 'how',\n",
       " 'is',\n",
       " 'our',\n",
       " 'little',\n",
       " 'find',\n",
       " 'the',\n",
       " 'wench',\n",
       " 'a',\n",
       " 'date',\n",
       " 'plan',\n",
       " 'progressing',\n",
       " 'forget',\n",
       " 'french',\n",
       " 'thats',\n",
       " 'because',\n",
       " 'its',\n",
       " 'such',\n",
       " 'a',\n",
       " 'nice',\n",
       " 'one',\n",
       " 'i',\n",
       " 'dont',\n",
       " 'want',\n",
       " 'to',\n",
       " 'know',\n",
       " 'how',\n",
       " 'to',\n",
       " 'say',\n",
       " 'that',\n",
       " 'though',\n",
       " 'i',\n",
       " 'want',\n",
       " 'to',\n",
       " 'know',\n",
       " 'useful',\n",
       " 'things',\n",
       " 'like',\n",
       " 'where',\n",
       " 'the',\n",
       " 'good',\n",
       " 'stores',\n",
       " 'are',\n",
       " 'how',\n",
       " 'much',\n",
       " 'does',\n",
       " 'champagne',\n",
       " 'cost',\n",
       " 'stuff',\n",
       " 'like',\n",
       " 'chat',\n",
       " 'i',\n",
       " 'have',\n",
       " 'never',\n",
       " 'in',\n",
       " 'my',\n",
       " 'life',\n",
       " 'had',\n",
       " 'to',\n",
       " 'point',\n",
       " 'out',\n",
       " 'my',\n",
       " 'head',\n",
       " 'to',\n",
       " 'someone',\n",
       " 'right',\n",
       " 'see',\n",
       " 'youre',\n",
       " 'ready',\n",
       " 'for',\n",
       " 'the',\n",
       " 'quiz',\n",
       " 'cesc',\n",
       " 'ma',\n",
       " 'tete',\n",
       " 'this',\n",
       " 'is',\n",
       " 'my',\n",
       " 'head',\n",
       " 'let',\n",
       " 'me',\n",
       " 'see',\n",
       " 'what',\n",
       " 'i',\n",
       " 'can',\n",
       " 'do',\n",
       " 'gosh',\n",
       " 'if',\n",
       " 'only',\n",
       " 'we',\n",
       " 'could',\n",
       " 'find',\n",
       " 'kat',\n",
       " 'a',\n",
       " 'boyfriend',\n",
       " 'thats',\n",
       " 'a',\n",
       " 'shame',\n",
       " 'unsolved',\n",
       " 'mystery',\n",
       " 'she',\n",
       " 'used',\n",
       " 'to',\n",
       " 'be',\n",
       " 'really',\n",
       " 'popular',\n",
       " 'when',\n",
       " 'she',\n",
       " 'started',\n",
       " 'high',\n",
       " 'school',\n",
       " 'then',\n",
       " 'it',\n",
       " 'was',\n",
       " 'just',\n",
       " 'like',\n",
       " 'she',\n",
       " 'got',\n",
       " 'sick',\n",
       " 'of',\n",
       " 'it',\n",
       " 'or',\n",
       " 'something',\n",
       " 'why',\n",
       " 'seems',\n",
       " 'like',\n",
       " 'she',\n",
       " 'could',\n",
       " 'get',\n",
       " 'a',\n",
       " 'date',\n",
       " 'easy',\n",
       " 'enough',\n",
       " 'the',\n",
       " 'thing',\n",
       " 'is',\n",
       " 'im',\n",
       " 'at',\n",
       " 'the',\n",
       " 'mercy',\n",
       " 'of',\n",
       " 'a',\n",
       " 'particularly',\n",
       " 'hideous',\n",
       " 'breed',\n",
       " 'of',\n",
       " 'loser',\n",
       " 'my',\n",
       " 'sister',\n",
       " 'i',\n",
       " 'cant',\n",
       " 'date',\n",
       " 'until',\n",
       " 'she',\n",
       " 'does',\n",
       " 'no',\n",
       " 'no',\n",
       " 'its',\n",
       " 'my',\n",
       " 'fault',\n",
       " 'we',\n",
       " 'didnt',\n",
       " 'have',\n",
       " 'a',\n",
       " 'proper',\n",
       " 'introduction',\n",
       " 'forget',\n",
       " 'it',\n",
       " 'youre',\n",
       " 'asking',\n",
       " 'me',\n",
       " 'out',\n",
       " 'thats',\n",
       " 'so',\n",
       " 'cute',\n",
       " 'whats',\n",
       " 'your',\n",
       " 'name',\n",
       " 'again',\n",
       " 'okay',\n",
       " 'then',\n",
       " 'how',\n",
       " 'bout',\n",
       " 'we',\n",
       " 'try',\n",
       " 'out',\n",
       " 'some',\n",
       " 'french',\n",
       " 'cuisine',\n",
       " 'saturday',\n",
       " 'night',\n",
       " 'not',\n",
       " 'the',\n",
       " 'hacking',\n",
       " 'and',\n",
       " 'gagging',\n",
       " 'and',\n",
       " 'spitting',\n",
       " 'part',\n",
       " 'please',\n",
       " 'well',\n",
       " 'i',\n",
       " 'thought',\n",
       " 'wed',\n",
       " 'start',\n",
       " 'with',\n",
       " 'pronunciation',\n",
       " 'if',\n",
       " 'thats',\n",
       " 'okay',\n",
       " 'with',\n",
       " 'you',\n",
       " 'can',\n",
       " 'we',\n",
       " 'make',\n",
       " 'this',\n",
       " 'quick',\n",
       " 'roxanne',\n",
       " 'korrine',\n",
       " 'and',\n",
       " 'andrew',\n",
       " 'barrett',\n",
       " 'are',\n",
       " 'having',\n",
       " 'an',\n",
       " 'incredibly',\n",
       " 'horrendous',\n",
       " 'public',\n",
       " 'break',\n",
       " 'up',\n",
       " 'on',\n",
       " 'the',\n",
       " 'quad',\n",
       " 'again',\n",
       " 'i',\n",
       " 'did',\n",
       " 'you',\n",
       " 'think',\n",
       " 'you',\n",
       " 're',\n",
       " 'the',\n",
       " 'only',\n",
       " 'sophomore',\n",
       " 'at',\n",
       " 'the',\n",
       " 'prom',\n",
       " 'i',\n",
       " 'dont',\n",
       " 'have',\n",
       " 'to',\n",
       " 'be',\n",
       " 'home',\n",
       " 'til',\n",
       " 'two',\n",
       " 'i',\n",
       " 'have',\n",
       " 'to',\n",
       " 'be',\n",
       " 'home',\n",
       " 'in',\n",
       " 'twenty',\n",
       " 'minutes',\n",
       " 'all',\n",
       " 'i',\n",
       " 'know',\n",
       " 'is',\n",
       " 'id',\n",
       " 'give',\n",
       " 'up',\n",
       " 'my',\n",
       " 'private',\n",
       " 'line',\n",
       " 'to',\n",
       " 'go',\n",
       " 'out',\n",
       " 'with',\n",
       " 'a',\n",
       " 'guy',\n",
       " 'like',\n",
       " 'joey',\n",
       " 'sometimes',\n",
       " 'i',\n",
       " 'wonder',\n",
       " 'if',\n",
       " 'the',\n",
       " 'guys',\n",
       " 'were',\n",
       " 'supposed',\n",
       " 'to',\n",
       " 'want',\n",
       " 'to',\n",
       " 'go',\n",
       " 'out',\n",
       " 'with',\n",
       " 'are',\n",
       " 'the',\n",
       " 'ones',\n",
       " 'we',\n",
       " 'actually',\n",
       " 'want',\n",
       " 'to',\n",
       " 'go',\n",
       " 'out',\n",
       " 'with',\n",
       " 'you',\n",
       " 'know',\n",
       " 'i',\n",
       " 'dont',\n",
       " 'think',\n",
       " 'the',\n",
       " 'highlights',\n",
       " 'of',\n",
       " 'dating',\n",
       " 'joey',\n",
       " 'dorsey',\n",
       " 'are',\n",
       " 'going',\n",
       " 'to',\n",
       " 'include',\n",
       " 'dooropening',\n",
       " 'and',\n",
       " 'coatholding',\n",
       " 'combination',\n",
       " 'i',\n",
       " 'dont',\n",
       " 'know',\n",
       " 'i',\n",
       " 'thought',\n",
       " 'hed',\n",
       " 'be',\n",
       " 'different',\n",
       " 'more',\n",
       " 'of',\n",
       " 'a',\n",
       " 'gentleman',\n",
       " 'is',\n",
       " 'he',\n",
       " 'oily',\n",
       " 'or',\n",
       " 'dry',\n",
       " 'he',\n",
       " 'practically',\n",
       " 'proposed',\n",
       " 'when',\n",
       " 'he',\n",
       " 'found',\n",
       " 'out',\n",
       " 'we',\n",
       " 'had',\n",
       " 'the',\n",
       " 'same',\n",
       " 'dermatologist',\n",
       " 'i',\n",
       " 'mean',\n",
       " 'dr',\n",
       " 'bonchowski',\n",
       " 'is',\n",
       " 'great',\n",
       " 'an',\n",
       " 'all',\n",
       " 'but',\n",
       " 'hes',\n",
       " 'not',\n",
       " 'exactly',\n",
       " 'relevant',\n",
       " 'party',\n",
       " 'conversation',\n",
       " 'would',\n",
       " 'you',\n",
       " 'mind',\n",
       " 'getting',\n",
       " 'me',\n",
       " 'a',\n",
       " 'drink',\n",
       " 'great',\n",
       " 'joey',\n",
       " 'who',\n",
       " 'where',\n",
       " 'did',\n",
       " 'he',\n",
       " 'go',\n",
       " 'he',\n",
       " 'was',\n",
       " 'just',\n",
       " 'here',\n",
       " 'you',\n",
       " 'might',\n",
       " 'wanna',\n",
       " 'think',\n",
       " 'about',\n",
       " 'it',\n",
       " 'no',\n",
       " 'did',\n",
       " 'you',\n",
       " 'change',\n",
       " 'your',\n",
       " 'hair',\n",
       " 'you',\n",
       " 'know',\n",
       " 'the',\n",
       " 'deal',\n",
       " 'i',\n",
       " 'can',\n",
       " 't',\n",
       " 'go',\n",
       " 'if',\n",
       " 'kat',\n",
       " 'doesnt',\n",
       " 'go',\n",
       " 'listen',\n",
       " 'i',\n",
       " 'want',\n",
       " 'to',\n",
       " 'talk',\n",
       " 'to',\n",
       " 'you',\n",
       " 'about',\n",
       " 'the',\n",
       " 'prom',\n",
       " 'youre',\n",
       " 'concentrating',\n",
       " 'awfully',\n",
       " 'hard',\n",
       " 'considering',\n",
       " 'its',\n",
       " 'gym',\n",
       " 'class',\n",
       " 'hi',\n",
       " 'joey',\n",
       " 'hey',\n",
       " 'sweet',\n",
       " 'cheeks',\n",
       " 'my',\n",
       " 'agent',\n",
       " 'says',\n",
       " 'ive',\n",
       " 'got',\n",
       " 'a',\n",
       " 'good',\n",
       " 'shot',\n",
       " 'at',\n",
       " 'being',\n",
       " 'the',\n",
       " 'prada',\n",
       " 'guy',\n",
       " 'next',\n",
       " 'year',\n",
       " 'neat',\n",
       " 'its',\n",
       " 'a',\n",
       " 'cruise',\n",
       " 'line',\n",
       " 'but',\n",
       " 'ill',\n",
       " 'be',\n",
       " 'like',\n",
       " 'wearing',\n",
       " 'a',\n",
       " 'uniform',\n",
       " 'and',\n",
       " 'stuff',\n",
       " 'queen',\n",
       " 'harry',\n",
       " 'so',\n",
       " 'yeah',\n",
       " 'ive',\n",
       " 'got',\n",
       " 'the',\n",
       " 'sears',\n",
       " 'catalog',\n",
       " 'thing',\n",
       " 'going',\n",
       " 'and',\n",
       " 'the',\n",
       " 'tube',\n",
       " 'sock',\n",
       " 'gig',\n",
       " 'thats',\n",
       " 'gonna',\n",
       " 'be',\n",
       " 'huge',\n",
       " 'and',\n",
       " 'then',\n",
       " 'im',\n",
       " 'up',\n",
       " 'for',\n",
       " 'an',\n",
       " 'ad',\n",
       " 'for',\n",
       " 'queen',\n",
       " 'harry',\n",
       " 'next',\n",
       " 'week',\n",
       " 'hopefully',\n",
       " 'exactly',\n",
       " 'so',\n",
       " 'you',\n",
       " 'going',\n",
       " 'to',\n",
       " 'bogey',\n",
       " 'lowenbraus',\n",
       " 'thing',\n",
       " 'on',\n",
       " 'saturday',\n",
       " 'expensive']"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(834, 1)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_line_array = np.array([movie_lines])\n",
    "movie_line_array= movie_line_array.reshape(-1,1)\n",
    "movie_line_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelEncoder = preprocessing.LabelEncoder()\n",
    "movie_line_labels = labelEncoder.fit_transform(lines_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([72, 73, 30, 58, 41, 87, 53, 48, 34, 42, 67, 80, 28, 64, 45, 79, 99,\n",
       "       51, 69, 88,  3, 70, 77, 94, 33, 31, 74, 15, 23, 91, 44, 19, 83, 60,\n",
       "       39, 59, 35, 32, 63,  8, 21, 98, 90, 24, 89, 82, 71, 78, 22, 11, 66,\n",
       "       27, 56,  4, 40, 13, 65, 75, 85, 57, 68,  1, 49, 12, 96, 54, 52, 76,\n",
       "        5, 25, 95, 26, 29,  2, 62,  0,  6, 36, 16, 86, 14, 38, 84, 81, 93,\n",
       "       50,  7, 92, 43, 97, 18, 17, 46, 47, 37, 55, 61, 20,  9, 10],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_line_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100,), (100, 1))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_line_labels.shape, movie_line_labels.reshape(-1,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dwight\\Anaconda3\\envs\\packt\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:363: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "wordOneHotEncoder = preprocessing.OneHotEncoder()\n",
    "\n",
    "line_onehot = wordOneHotEncoder.fit_transform(movie_line_labels.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line_onehot.toarray()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordOneHotEncoder = preprocessing.OneHotEncoder()\n",
    "\n",
    "wordOneHotEncoder.fit(movie_line_array)\n",
    "line_onehot = wordOneHotEncoder.transform(movie_line_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<834x368 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 834 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line_onehot.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:packt]",
   "language": "python",
   "name": "conda-env-packt-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
